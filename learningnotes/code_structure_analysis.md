# DeepInflation ä»£ç ç»“æ„è¯¦è§£

![ç³»ç»Ÿæ¶æ„å›¾](architecture.png)

## ä¸€ã€ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ

DeepInflation æ˜¯ä¸€ä¸ªåŸºäºå¤šæ™ºèƒ½ä½“åä½œçš„å®‡å®™å­¦åŠ¿èƒ½åˆ†æç³»ç»Ÿ,ç”¨äºç ”ç©¶æš´èƒ€å®‡å®™å­¦æ¨¡å‹ã€‚æ ¹æ®æ¶æ„å›¾,æ•´ä¸ªç³»ç»Ÿåˆ†ä¸ºä»¥ä¸‹å‡ ä¸ªæ ¸å¿ƒç»„ä»¶:

### æ ¸å¿ƒç»„ä»¶æ˜ å°„

| æ¶æ„å›¾ç»„ä»¶ | ä»£ç å®ç° | ä¸»è¦æ–‡ä»¶ |
|-----------|---------|---------|
| **User Interface** | Gradio Webç•Œé¢ | [app.py](file:///home/phan635/HybridAutomata/baseline_ha/DeepInflation-pq/app.py) |
| **Main Agent (Orchestrator)** | ä¸»ç¼–æ’æ™ºèƒ½ä½“ | [agent.py](file:///home/phan635/HybridAutomata/baseline_ha/DeepInflation-pq/deepinflation/agent.py) |
| **Knowledge Base** | RAGå‘é‡æ•°æ®åº“ | [encyclopedia_rag.py](file:///home/phan635/HybridAutomata/baseline_ha/DeepInflation-pq/deepinflation/encyclopedia_rag.py) |
| **SR Sub-Agent** | ç¬¦å·å›å½’å­æ™ºèƒ½ä½“ | [agent.py](file:///home/phan635/HybridAutomata/baseline_ha/DeepInflation-pq/deepinflation/agent.py#L321-L331) |
| **Analysis Tools** | åŠ¿èƒ½åˆ†æå·¥å…· | [tools.py](file:///home/phan635/HybridAutomata/baseline_ha/DeepInflation-pq/deepinflation/tools.py) |
| **PySR** | ç¬¦å·å›å½’å¼•æ“ | [sr_search.py](file:///home/phan635/HybridAutomata/baseline_ha/DeepInflation-pq/deepinflation/sr_search.py) |
| **Physics Kernel** | Juliaç‰©ç†è®¡ç®—æ ¸å¿ƒ | [sr_search.py](file:///home/phan635/HybridAutomata/baseline_ha/DeepInflation-pq/deepinflation/sr_search.py#L25-L208) |

---

## äºŒã€å„æ¨¡å—è¯¦ç»†è®²è§£

### ğŸ“± 1. User Interface (app.py)

**åŠŸèƒ½**: æä¾›åŸºäº Gradio çš„ Web äº¤äº’ç•Œé¢,æ”¯æŒæµå¼å¯¹è¯å’Œå·¥å…·çŠ¶æ€æ˜¾ç¤ºã€‚

#### æ ¸å¿ƒæµç¨‹

```mermaid
graph LR
    A[ç”¨æˆ·è¾“å…¥] --> B[display_user_message]
    B --> C[respond å¼‚æ­¥æµå¼å¤„ç†]
    C --> D{äº‹ä»¶ç±»å‹}
    D -->|tool_start| E[æ˜¾ç¤ºå·¥å…·å¼€å§‹]
    D -->|tool_end| F[æ˜¾ç¤ºå·¥å…·å®Œæˆ]
    D -->|text_delta| G[æµå¼è¾“å‡ºæ–‡æœ¬]
    D -->|response| H[æœ€ç»ˆå“åº”]
```

#### å…³é”®å‡½æ•°

- **`initialize_agent`** ([app.py:L23-L52](file:///home/phan635/HybridAutomata/baseline_ha/DeepInflation-pq/app.py#L23-L52)): åˆå§‹åŒ– DeepInflation æ™ºèƒ½ä½“
  ```python
  agent = DeepInflation(
      api_key=api_key,
      base_url=base_url,
      model=model,
      embedding_model=embedding_model,
      verbose=False
  )
  ```

- **`respond`** ([app.py:L79-L191](file:///home/phan635/HybridAutomata/baseline_ha/DeepInflation-pq/app.py#L79-L191)): å¼‚æ­¥æµå¼å“åº”å¤„ç†å™¨
  - ç›‘å¬ `agent.stream()` ç”Ÿæˆçš„äº‹ä»¶æµ
  - å¤„ç†å·¥å…·è°ƒç”¨çŠ¶æ€ (`tool_start`, `tool_end`)
  - å®æ—¶æ›´æ–° UI æ˜¾ç¤º

---

### ğŸ§  2. Main Agent - ä¸»ç¼–æ’æ™ºèƒ½ä½“ (agent.py)

**åŠŸèƒ½**: ç³»ç»Ÿçš„æ ¸å¿ƒæ§åˆ¶å™¨,è´Ÿè´£åè°ƒæ‰€æœ‰å·¥å…·å’Œå­æ™ºèƒ½ä½“,é‡‡ç”¨ **ReAct** (Reasoning + Acting) æ¨¡å¼ã€‚

#### æ¶æ„è®¾è®¡

```mermaid
graph TD
    A[DeepInflation Agent] --> B[Team - å›¢é˜Ÿæ¨¡å¼]
    B --> C[Main Agent Tools]
    B --> D[SR Sub-Agent]
    C --> E[analyze_potential]
    C --> F[plot_potential]
    C --> G[search_encyclopedia]
    D --> H[search_potential]
```

#### æ ¸å¿ƒç±»ä¸æ–¹æ³•

**DeepInflation ç±»** ([agent.py:L265-L481](file:///home/phan635/HybridAutomata/baseline_ha/DeepInflation-pq/deepinflation/agent.py#L265-L481))

```python
class DeepInflation:
    def __init__(self, api_key, base_url, model, embedding_model, temperature, verbose):
        # 1. åˆå§‹åŒ– OpenAI æ¨¡å‹
        self._model = OpenAILike(id=model, api_key=api_key, ...)
        
        # 2. åˆå§‹åŒ–çŸ¥è¯†åº“ RAG
        init_rag(api_key=api_key, embedding_model=embedding_model)
        
        # 3. åˆ›å»ºæ™ºèƒ½ä½“å›¢é˜Ÿ
        self.team = self._create_team()
```

**å›¢é˜Ÿåˆ›å»º** ([agent.py:L320-L343](file:///home/phan635/HybridAutomata/baseline_ha/DeepInflation-pq/deepinflation/agent.py#L320-L343))

```python
def _create_team(self):
    # åˆ›å»º SR å­æ™ºèƒ½ä½“
    sr_agent = Agent(
        name="SR Agent",
        instructions=SR_AGENT_PROMPT,  # ç¬¦å·å›å½’ä¸“å®¶æç¤ºè¯
        tools=[search_potential]       # å”¯ä¸€å·¥å…·: ç¬¦å·å›å½’æœç´¢
    )
    
    # åˆ›å»ºä¸»å›¢é˜Ÿ
    return Team(
        name="Inflation Research Team",
        members=[sr_agent],           # åŒ…å« SR å­æ™ºèƒ½ä½“
        tools=[analyze_potential, plot_potential, search_encyclopedia],
        instructions=MAIN_AGENT_PROMPT  # ä¸»æ™ºèƒ½ä½“æç¤ºè¯
    )
```

#### å†³ç­–æ ‘ (æ¥è‡ª Prompt)

ä¸»æ™ºèƒ½ä½“æ ¹æ®ç”¨æˆ·è¯·æ±‚è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„å·¥å…·æˆ–å§”æ‰˜å­æ™ºèƒ½ä½“:

```
ç”¨æˆ·è¯·æ±‚
â”œâ”€ "V = ... çš„ ns/r æ˜¯å¤šå°‘?" â†’ analyze_potential
â”œâ”€ "ç»˜åˆ¶åŠ¿èƒ½å›¾ V = ..." â†’ plot_potential
â”œâ”€ "ä»€ä¹ˆæ˜¯ [æ¨¡å‹å]?" â†’ search_encyclopedia
â””â”€ "æ‰¾ä¸€ä¸ªæ»¡è¶³ nsâ‰ˆ... çš„åŠ¿èƒ½" â†’ å§”æ‰˜ç»™ SR Sub-Agent
```

#### æµå¼è¾“å‡ºæœºåˆ¶

**`stream` æ–¹æ³•** ([agent.py:L345-L461](file:///home/phan635/HybridAutomata/baseline_ha/DeepInflation-pq/deepinflation/agent.py#L345-L461))

```python
async def stream(self, question: str):
    """å¼‚æ­¥ç”Ÿæˆäº‹ä»¶æµä¾› Gradio æ¶ˆè´¹"""
    async for event in self.team.arun(input=question, stream=True, stream_events=True):
        # æ£€æµ‹å·¥å…·è°ƒç”¨å¼€å§‹
        if event.event == TeamRunEvent.tool_call_started:
            yield {"type": "tool_start", "call_id": ..., "info": ..., "args": ...}
        
        # æ£€æµ‹å·¥å…·è°ƒç”¨å®Œæˆ
        elif event.event == TeamRunEvent.tool_call_completed:
            yield {"type": "tool_end", "call_id": ..., "duration": ...}
        
        # æµå¼æ–‡æœ¬è¾“å‡º
        elif event.event == TeamRunEvent.run_content:
            yield {"type": "text_delta", "delta": event.content}
```

---

### ğŸ“š 3. Database - å¯¹è¯å†å²ç®¡ç† (SqliteDb)

**åŠŸèƒ½**: æŒä¹…åŒ–å­˜å‚¨å¯¹è¯å†å²,æ”¯æŒå¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡ç®¡ç†,ç”± Agno æ¡†æ¶çš„ `SqliteDb` æä¾›ã€‚

#### åˆå§‹åŒ–ä¸é…ç½®

**æ•°æ®åº“åˆ›å»º** ([agent.py:L307-L310](file:///home/phan635/HybridAutomata/baseline_ha/DeepInflation-pq/deepinflation/agent.py#L307-L310))

```python
self._db = SqliteDb(
    db_file="tmp/agent_storage.db",           # æ•°æ®åº“æ–‡ä»¶è·¯å¾„
    session_table="inflation_agent_sessions",  # ä¼šè¯è¡¨å
)
```

**ä¼ é€’ç»™ Team** ([agent.py:L340](file:///home/phan635/HybridAutomata/baseline_ha/DeepInflation-pq/deepinflation/agent.py#L340))

```python
return Team(
    name="Inflation Research Team",
    model=self._model,
    members=[sr_agent],
    tools=[analyze_potential, plot_potential, search_encyclopedia],
    instructions=MAIN_AGENT_PROMPT,
    db=self._db,                      # â† è¿æ¥æ•°æ®åº“
    add_history_to_context=True,      # â† å¯ç”¨å†å²è®°å½•
    num_history_runs=5,                # â† ä¿ç•™æœ€è¿‘ 5 è½®å¯¹è¯
)
```

#### æ•°æ®å­˜å‚¨å†…å®¹

æ•°æ®åº“è‡ªåŠ¨ä¿å­˜ä»¥ä¸‹å†…å®¹:

| æ•°æ®ç±»å‹ | è¯´æ˜ | ç¤ºä¾‹ |
|---------|------|------|
| **ç”¨æˆ·æ¶ˆæ¯** | ç”¨æˆ·çš„åŸå§‹è¾“å…¥ | "What is ns for V=phi^2?" |
| **AI å›å¤** | åŠ©æ‰‹çš„å®Œæ•´å“åº” | "å¯¹äº V=Ï†Â²,æ ‡é‡è°±æŒ‡æ•° nsâ‰ˆ0.967..." |
| **å·¥å…·è°ƒç”¨** | å·¥å…·åç§° + å‚æ•° + ç»“æœ | `analyze_potential("phi^2") â†’ {...}` |
| **ç³»ç»Ÿæ¶ˆæ¯** | Prompt æŒ‡ä»¤ | MAIN_AGENT_PROMPT å†…å®¹ |
| **ä¼šè¯å…ƒæ•°æ®** | æ—¶é—´æˆ³ã€session_id | `2026-02-04T17:53:30, uuid-1234...` |

#### å·¥ä½œæµç¨‹

```mermaid
sequenceDiagram
    participant User
    participant DeepInflation
    participant Team
    participant SqliteDb
    
    User->>DeepInflation: ç¬¬1æ¬¡æé—®
    DeepInflation->>Team: arun(question, session_id)
    Team->>Team: å¤„ç†è¯·æ±‚ + è°ƒç”¨å·¥å…·
    Team->>SqliteDb: ä¿å­˜æ¶ˆæ¯å†å²
    Team-->>DeepInflation: è¿”å›å“åº”
    
    User->>DeepInflation: ç¬¬2æ¬¡æé—®
    DeepInflation->>Team: arun(question, session_id)
    Team->>SqliteDb: åŠ è½½æœ€è¿‘5è½®å†å²
    SqliteDb-->>Team: è¿”å›å†å²æ¶ˆæ¯
    Team->>Team: å°†å†å²æ·»åŠ åˆ°ä¸Šä¸‹æ–‡
    Team->>Team: åŸºäºä¸Šä¸‹æ–‡å¤„ç†æ–°è¯·æ±‚
    Team->>SqliteDb: ä¿å­˜æ–°ä¸€è½®æ¶ˆæ¯
    Team-->>DeepInflation: è¿”å›å“åº”
```

#### ä¼šè¯ç®¡ç†æœºåˆ¶

**1. Session ID ç”Ÿæˆ** ([agent.py:L316](file:///home/phan635/HybridAutomata/baseline_ha/DeepInflation-pq/deepinflation/agent.py#L316))

```python
self.session_id = str(uuid4())  # å”¯ä¸€ä¼šè¯æ ‡è¯†ç¬¦
```

**2. ä½¿ç”¨ Session ID æŸ¥è¯¢** ([agent.py:L364](file:///home/phan635/HybridAutomata/baseline_ha/DeepInflation-pq/deepinflation/agent.py#L364))

```python
async for event in self.team.arun(
    input=question,
    stream=True,
    session_id=self.session_id,  # Agno è‡ªåŠ¨åŠ è½½æ­¤ session çš„å†å²
):
```

**3. æ¸…ç©ºå†å²** ([agent.py:L475-L480](file:///home/phan635/HybridAutomata/baseline_ha/DeepInflation-pq/deepinflation/agent.py#L475-L480))

```python
def clear_history(self):
    """ç”Ÿæˆæ–° session_id,å¼€å§‹å…¨æ–°å¯¹è¯"""
    self.session_id = str(uuid4())  # æ–°ä¼šè¯ä¸ä¼šåŠ è½½æ—§å†å²
    self.last_plot_path = None
```

#### å®é™…ä½¿ç”¨ç¤ºä¾‹

```python
# åœºæ™¯: å¤šè½®å¯¹è¯

# ç¬¬ 1 è½®
user: "What is V for Starobinsky model?"
ai: "The Starobinsky model has potential V = (1-exp(-âˆš(2/3)Ï†))Â²"
# â†’ ä¿å­˜åˆ° session_A

# ç¬¬ 2 è½® (AI èƒ½è®°ä½ç¬¬ 1 è½®å†…å®¹)
user: "Calculate ns and r for it"
ai: "For the Starobinsky model (V=(1-exp(-âˆš(2/3)Ï†))Â²), nsâ‰ˆ0.965, râ‰ˆ0.003"
# â†’ åŠ è½½ session_A å†å² + ä¿å­˜æ–°å¯¹è¯

# ç¬¬ 3 è½®
user: "Plot this potential"
ai: [è°ƒç”¨ plot_potential("(1-exp(-sqrt(2/3)*phi))^2")]
# â†’ AI çŸ¥é“ "this potential" æŒ‡çš„æ˜¯ Starobinsky æ¨¡å‹

# æ¸…ç©ºå†å²
agent.clear_history()

# ç¬¬ 4 è½® (æ–°ä¼šè¯)
user: "Plot this potential"
ai: "Which potential do you want to plot?"  # ä¸è®°å¾—ä¹‹å‰çš„å¯¹è¯
```

#### æ•°æ®åº“ vs RAG å¯¹æ¯”

| ç‰¹æ€§ | **Database (å¯¹è¯å†å²)** | **RAG (çŸ¥è¯†åº“)** |
|------|----------------------|----------------|
| **æ•°æ®æ¥æº** | å½“å‰ç”¨æˆ·çš„å®æ—¶å¯¹è¯ | é¢„å…ˆå‡†å¤‡çš„ä¸“ä¸šæ–‡æ¡£ |
| **å­˜å‚¨ä½ç½®** | `tmp/agent_storage.db` | `tmp/lancedb/` |
| **åŠ è½½æ–¹å¼** | æŒ‰ `session_id` è‡ªåŠ¨åŠ è½½ | ä¸»åŠ¨è°ƒç”¨å·¥å…·æ£€ç´¢ |
| **æ›´æ–°é¢‘ç‡** | æ¯æ¬¡å¯¹è¯å®æ—¶æ›´æ–° | çŸ¥è¯†åº“é™æ€,å¯åŠ¨æ—¶åŠ è½½ |
| **ä½œç”¨** | è®°ä½ç”¨æˆ·å¯¹è¯ä¸Šä¸‹æ–‡ | æä¾›ä¸“ä¸šç‰©ç†çŸ¥è¯† |
| **ç”Ÿå‘½å‘¨æœŸ** | ä¼šè¯æŒä¹…åŒ–,å¯è·¨é‡å¯ | æŒä¹…åŒ–,ç›´åˆ°é‡å»ºç´¢å¼• |

---

### ğŸ“š 4. Knowledge Base - çŸ¥è¯†åº“ (encyclopedia_rag.py)

**åŠŸèƒ½**: åŸºäº **Parent Document Retrieval** çš„ RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆ) ç³»ç»Ÿ,å­˜å‚¨ 70+ æš´èƒ€å®‡å®™å­¦æ¨¡å‹æ–‡æ¡£,æä¾›ä¸“ä¸šçŸ¥è¯†æ£€ç´¢èƒ½åŠ›ã€‚

#### RAG ç³»ç»Ÿæ¶æ„

```mermaid
graph TB
    A[ç³»ç»Ÿå¯åŠ¨] --> B[åˆå§‹åŒ– RAG]
    B --> C[è¯»å– Markdown æ–‡æ¡£<br/>data/models/*.md]
    C --> D{æ–‡æ¡£å¤§å°åˆ¤æ–­}
    D -->|å°äº5000 tokens| E[æ•´æ–‡æ¡£ä½œä¸º Parent]
    D -->|å¤§äº5000 tokens| F[æŒ‰ H1 æ ‡é¢˜æ‹†åˆ†æˆ Sections]
    E --> G[åˆ‡åˆ†ä¸º 500 token Chunks]
    F --> G
    G --> H[æ‰¹é‡ç”Ÿæˆ Embeddings<br/>text-embedding-3-small]
    H --> I[å­˜å…¥ LanceDB å‘é‡åº“]
    I --> J[Parent Store å­—å…¸<br/>å­˜å‚¨å®Œæ•´æ–‡æ¡£]
    
    K[ç”¨æˆ·æŸ¥è¯¢] --> L[AI å†³ç­–è°ƒç”¨<br/>search_encyclopedia]
    L --> M[æŸ¥è¯¢å‘é‡åŒ–]
    M --> N[LanceDB æ··åˆæ£€ç´¢<br/>Semantic + BM25]
    N --> O[è·å– Top-N Chunks]
    O --> P[RRF èšåˆè¯„åˆ†]
    P --> Q[è¿”å› Top-3 Parent å®Œæ•´æ–‡æ¡£]
    Q --> R[AI åŸºäºæ–‡æ¡£ç”Ÿæˆå›ç­”]
```

#### æ ¸å¿ƒç±»ä¸åˆå§‹åŒ–

**EncyclopediaRAG ç±»** ([encyclopedia_rag.py:L42-L90](file:///home/phan635/HybridAutomata/baseline_ha/DeepInflation-pq/deepinflation/encyclopedia_rag.py#L42-L90))

```python
class EncyclopediaRAG:
    def __init__(self, api_key, base_url, embedding_model="text-embedding-3-small"):
        # 1. åˆå§‹åŒ– OpenAI Embedder
        self.embedder = OpenAIEmbedder(
            id=embedding_model,
            api_key=api_key,
            base_url=base_url,
            enable_batch=True,      # æ‰¹é‡å¤„ç†åŠ é€Ÿ
            batch_size=300
        )
        
        # 2. åˆå§‹åŒ–å‘é‡æ•°æ®åº“ (LanceDB)
        self.vector_db = LanceDb(
            uri="tmp/lancedb",
            table_name="encyclopedia_chunks",
            search_type=SearchType.hybrid  # æ··åˆæ£€ç´¢: è¯­ä¹‰ + å…³é”®è¯
        )
        
        # 3. çˆ¶æ–‡æ¡£å­˜å‚¨ (å†…å­˜å­—å…¸)
        self.parent_store = {}  # parent_id -> {title, content, metadata}
        
        # 4. æ„å»ºæˆ–åŠ è½½ç´¢å¼•
        if not self._index_exists():
            self._build_index()
```

#### ç´¢å¼•æ„å»ºæµç¨‹

**æ–‡æ¡£åˆ‡åˆ†ç­–ç•¥** ([encyclopedia_rag.py:L92-L141](file:///home/phan635/HybridAutomata/baseline_ha/DeepInflation-pq/deepinflation/encyclopedia_rag.py#L92-L141))

```python
def _build_index(self):
    for md_file in Path(MODELS_DIR).glob("*.md"):
        content = md_file.read_text()
        model_name = md_file.stem
        
        # æ ¹æ®å¤§å°å†³å®šåˆ‡åˆ†ç­–ç•¥
        if _tokens(content) <= 5000:
            # å°æ–‡æ¡£: æ•´ä¸ªä½œä¸ºä¸€ä¸ª Parent
            parents = [(model_name, content)]
        else:
            # å¤§æ–‡æ¡£: æŒ‰ H1 æ ‡é¢˜æ‹†åˆ†æˆå¤šä¸ª Section Parents
            parents = self._split_by_sections(content, model_name)
        
        # å¤„ç†æ¯ä¸ª Parent
        for title, text in parents:
            parent_id = md5(title.encode()).hexdigest()[:16]
            
            # å­˜å‚¨å®Œæ•´ Parent æ–‡æ¡£
            self.parent_store[parent_id] = {
                "title": title,
                "content": text,  # å®Œæ•´å†…å®¹,ç”¨äºè¿”å›
                "metadata": {...},
                "model": model_name
            }
            
            # å°† Parent åˆ‡åˆ†æˆå° Chunks ç”¨äºæ£€ç´¢
            for chunk in self._chunk_by_paragraphs(text):
                all_chunks.append((chunk, parent_id))
    
    # æ‰¹é‡ Embedding
    embeddings = self.embedder.async_get_embeddings_batch(chunks)
    
    # æ’å…¥å‘é‡åº“
    self.vector_db.table.add(data)
```

**ä¸ºä»€ä¹ˆç”¨ Parent-Chunk ç­–ç•¥?**

| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **æ£€ç´¢ç²¾åº¦** | å° Chunks (500 tokens) æé«˜è¯­ä¹‰åŒ¹é…ç²¾åº¦ |
| **ä¸Šä¸‹æ–‡å®Œæ•´æ€§** | è¿”å›å®Œæ•´ Parent æ–‡æ¡£,é¿å…ä¿¡æ¯ç¢ç‰‡åŒ– |
| **æ•ˆç‡** | åªéœ€å¯¹ Chunks å‘é‡åŒ–,Parent ç›´æ¥å­˜å‚¨ |

#### æ£€ç´¢ç®—æ³•: Reciprocal Rank Fusion (RRF)

**`search` æ–¹æ³•** ([encyclopedia_rag.py:L255-L275](file:///home/phan635/HybridAutomata/baseline_ha/DeepInflation-pq/deepinflation/encyclopedia_rag.py#L255-L275))

```python
def search(self, query: str, num_chunks=10, num_parents=3):
    """
    ä¸‰æ­¥æ£€ç´¢æµç¨‹:
    1. å‘é‡æ£€ç´¢ top-N chunks
    2. RRF ç®—æ³•èšåˆ parent åˆ†æ•°
    3. è¿”å› top-K parent å®Œæ•´æ–‡æ¡£
    """
    # Step 1: æ··åˆæ£€ç´¢ (è¯­ä¹‰ + BM25)
    chunk_results = self.vector_db.search(query, limit=num_chunks)
    
    # Step 2: RRF è¯„åˆ†èšåˆ
    scores = {}
    for rank, doc in enumerate(chunk_results):
        parent_id = doc.meta_data["parent_id"]
        # RRF å…¬å¼: score += 1/(k + rank), k=1
        scores[parent_id] = scores.get(parent_id, 0) + 1.0 / (rank + 2)
    
    # Step 3: è¿”å›å¾—åˆ†æœ€é«˜çš„ parent å®Œæ•´æ–‡æ¡£
    ranked_parents = sorted(scores.keys(), key=lambda p: scores[p], reverse=True)
    return [
        {**self.parent_store[pid], "score": scores[pid]} 
        for pid in ranked_parents[:num_parents]
    ]
```

**RRF ç®—æ³•ç¤ºä¾‹**:

```
å‡è®¾æ£€ç´¢åˆ° 10 ä¸ª chunks:
Chunk 1 (rank=0) â†’ Parent A: score += 1/(0+2) = 0.500
Chunk 2 (rank=1) â†’ Parent B: score += 1/(1+2) = 0.333
Chunk 3 (rank=2) â†’ Parent A: score += 1/(2+2) = 0.250  (ç´¯åŠ !)
Chunk 4 (rank=3) â†’ Parent C: score += 1/(3+2) = 0.200
...

æœ€ç»ˆåˆ†æ•°:
Parent A: 0.500 + 0.250 = 0.750 (æ’åç¬¬1,å¤šä¸ª chunks å‘½ä¸­)
Parent B: 0.333 (æ’åç¬¬2)
Parent C: 0.200 (æ’åç¬¬3)

è¿”å›: [Parent A å®Œæ•´æ–‡æ¡£, Parent B å®Œæ•´æ–‡æ¡£, Parent C å®Œæ•´æ–‡æ¡£]
```

**RRF çš„ä¼˜åŠ¿**: å¦‚æœä¸€ä¸ªçˆ¶æ–‡æ¡£æœ‰å¤šä¸ª chunks è¢«åŒ¹é…,å®ƒä¼šç§¯ç´¯æ›´é«˜åˆ†æ•°,æ›´æœ‰å¯èƒ½è¢«é€‰ä¸­ã€‚

#### ä½œä¸ºå·¥å…·é›†æˆåˆ° Agent

**å·¥å…·æ³¨å†Œ** ([agent.py:L336](file:///home/phan635/HybridAutomata/baseline_ha/DeepInflation-pq/deepinflation/agent.py#L336))

```python
Team(
    tools=[analyze_potential, plot_potential, search_encyclopedia],
    # search_encyclopedia æ˜¯ RAG å·¥å…·çš„å¯¹å¤–æ¥å£
)
```

**å·¥å…·å‡½æ•°** ([encyclopedia_rag.py:L296-L344](file:///home/phan635/HybridAutomata/baseline_ha/DeepInflation-pq/deepinflation/encyclopedia_rag.py#L296-L344))

```python
def search_encyclopedia(query: str, top_k: int = 3) -> str:
    """
    AI è°ƒç”¨æ­¤å·¥å…·æŸ¥è¯¢çŸ¥è¯†åº“
    
    Args:
        query: è‡ªç„¶è¯­è¨€æŸ¥è¯¢ (ä¾‹å¦‚: "Starobinsky model")
        top_k: è¿”å›æ–‡æ¡£æ•°é‡ (é»˜è®¤ 3, æœ€å¤§ 5)
    
    Returns:
        JSON æ ¼å¼ç»“æœ:
        {
            "success": True,
            "count": 3,
            "results": [
                {
                    "title": "Starobinsky Model",
                    "content": "å®Œæ•´æ¨¡å‹æ–‡æ¡£...",
                    "potential_latex": "$V = (1-e^{-\\sqrt{2/3}\\phi})^2$",
                    "parameters": "..."
                },
                ...
            ]
        }
    """
    results = _rag.search(query, num_chunks=4*top_k, num_parents=top_k)
    return json.dumps({"success": True, "results": results})
```

#### å®Œæ•´ä½¿ç”¨æµç¨‹

```mermaid
sequenceDiagram
    participant User
    participant AI_Agent
    participant search_encyclopedia
    participant VectorDB
    participant ParentStore
    
    User->>AI_Agent: "What is Starobinsky model?"
    AI_Agent->>AI_Agent: åˆ†æé—®é¢˜:<br/>éœ€è¦æŸ¥è¯¢çŸ¥è¯†åº“
    AI_Agent->>search_encyclopedia: query="Starobinsky model", top_k=3
    
    search_encyclopedia->>search_encyclopedia: æŸ¥è¯¢å‘é‡åŒ–
    search_encyclopedia->>VectorDB: æ··åˆæ£€ç´¢ Top 12 chunks
    VectorDB-->>search_encyclopedia: è¿”å› chunks + parent_id
    
    search_encyclopedia->>search_encyclopedia: RRF èšåˆè¯„åˆ†
    Note over search_encyclopedia: è®¡ç®—æ¯ä¸ª parent çš„ç´¯ç§¯åˆ†æ•°
    
    search_encyclopedia->>ParentStore: è·å– Top 3 parent å®Œæ•´æ–‡æ¡£
    ParentStore-->>search_encyclopedia: è¿”å›å®Œæ•´æ¨¡å‹æè¿°
    
    search_encyclopedia-->>AI_Agent: JSON ç»“æœ<br/>(title, content, potential)
    
    AI_Agent->>AI_Agent: åŸºäºæ£€ç´¢æ–‡æ¡£<br/>ç”Ÿæˆè‡ªç„¶è¯­è¨€å›ç­”
    AI_Agent-->>User: "Starobinsky æ¨¡å‹çš„åŠ¿èƒ½ä¸º...<br/>è¯¥æ¨¡å‹é¢„æµ‹ nsâ‰ˆ0.965, râ‰ˆ0.003<br/><br/>æ¥æº: EncyclopÃ¦dia Inflationaris"
```

#### RAG åˆå§‹åŒ–æ—¶æœº

**ç³»ç»Ÿå¯åŠ¨æ—¶åˆå§‹åŒ–** ([agent.py:L300-L305](file:///home/phan635/HybridAutomata/baseline_ha/DeepInflation-pq/deepinflation/agent.py#L300-L305))

```python
class DeepInflation:
    def __init__(self, ...):
        # åœ¨åˆ›å»º Agent å‰åˆå§‹åŒ– RAG (å•ä¾‹æ¨¡å¼)
        init_rag(
            api_key=self._api_key,
            base_url=self._base_url,
            embedding_model=embedding_model
        )
        # RAG åˆå§‹åŒ–å,æ‰€æœ‰ Agent éƒ½å¯ä»¥ä½¿ç”¨ search_encyclopedia å·¥å…·
```

#### çŸ¥è¯†åº“å†…å®¹

| ç±»åˆ« | å†…å®¹ | æ¥æº |
|------|------|------|
| **æ¨¡å‹æ–‡æ¡£** | 70+ ä¸ª Markdown æ–‡ä»¶ | `data/models/*.md` |
| **å…ƒæ•°æ®** | åŠ¿èƒ½è¡¨è¾¾å¼ã€å‚æ•° | `data/model_list.json` |
| **æ–‡çŒ®æ¥æº** | EncyclopÃ¦dia Inflationaris | [arXiv:1303.3787](https://arxiv.org/abs/1303.3787) |

**çŸ¥è¯†åº“ç¤ºä¾‹æ–‡æ¡£ç»“æ„**:

```markdown
# Starobinsky Model

The Starobinsky model is one of the earliest and most successful...

## Potential
$V(\phi) = (1 - e^{-\sqrt{2/3}\phi})^2$

## Predictions
- Spectral index: $n_s \approx 0.965$
- Tensor-to-scalar ratio: $r \approx 0.003$

## Theoretical Background
This model arises from $R^2$ gravity...
```

---

### ğŸ”¬ 4. Analysis Tools - åˆ†æå·¥å…· (tools.py)

**åŠŸèƒ½**: æä¾›ä¸¤ä¸ªæ ¸å¿ƒç‰©ç†è®¡ç®—å·¥å…·,åŸºäº [inflation.py](file:///home/phan635/HybridAutomata/baseline_ha/DeepInflation-pq/deepinflation/inflation.py) çš„è®¡ç®—å¼•æ“ã€‚

#### å·¥å…· 1: `analyze_potential` (è®¡ç®—è§‚æµ‹é‡)

**è¾“å…¥**: åŠ¿èƒ½è¡¨è¾¾å¼ `V(Ï†)`,ä¾‹å¦‚ `phi^2` æˆ– `(1-exp(-0.816*phi))^2`  
**è¾“å‡º**: JSON æ ¼å¼çš„æ‰€æœ‰æœ‰æ•ˆè½¨è¿¹çš„è§‚æµ‹é‡ `(ns, r, A_s)`

**è°ƒç”¨é“¾**:
```
analyze_potential(expression)
  â†“
compute_observables_all_trajectories(expression)  # inflation.py
  â†“
compute_observables(V, V', V'', phi_min, phi_max)
  â†“
[æ‰¾åˆ° Îµ=1 çš„ phi_end â†’ ç§¯åˆ†æ±‚ phi_N â†’ è®¡ç®— ns, r, A_s]
```

**å…³é”®ç‰©ç†é‡è®¡ç®—** ([inflation.py:L68-L81](file:///home/phan635/HybridAutomata/baseline_ha/DeepInflation-pq/deepinflation/inflation.py#L68-L81)):

```python
# æ…¢æ»šå‚æ•° Îµ = (M_PÂ²/2)(V'/V)Â²
def epsilon(V, V_prime, phi):
    return (M_P2 / 2) * (V_prime(phi) / V(phi))**2

# è§‚æµ‹é‡è®¡ç®—
ns = 1.0 - 6.0*Îµ_N + 2.0*Î·_N  # æ ‡é‡è°±æŒ‡æ•°
r = 16.0 * Îµ_N                # å¼ æ ‡æ¯”
A_s = V(phi_N) / (24*Ï€Â²*M_PÂ²Â²*Îµ_N)  # åŠŸç‡è°±å¹…åº¦
```

#### å·¥å…· 2: `plot_potential` (ç”Ÿæˆè¯Šæ–­å›¾)

**è¾“å…¥**: åŠ¿èƒ½è¡¨è¾¾å¼ + è¾“å‡ºè·¯å¾„  
**è¾“å‡º**: 3 é¢æ¿è¯Šæ–­å›¾ PNG æ–‡ä»¶

**ä¸‰ä¸ªé¢æ¿å†…å®¹**:
1. **Panel 1**: V(Ï†) æ›²çº¿ + è½¨è¿¹æ ‡è®°ç‚¹ (Ï†_end, N=50, N=60)
2. **Panel 2**: æ…¢æ»šå‚æ•° Îµ(Ï†), Î·(Ï†) çš„å¯¹æ•°å›¾
3. **Panel 3**: (ns, r) å¹³é¢ä¸Šçš„é¢„æµ‹å€¼ vs Planck+BK18 è§‚æµ‹åéªŒ

**ç»˜å›¾ä»£ç ç¤ºä¾‹** ([tools.py:L106-L194](file:///home/phan635/HybridAutomata/baseline_ha/DeepInflation-pq/deepinflation/tools.py#L106-L194)):

```python
# Panel 1: åŠ¿èƒ½æ›²çº¿
axes[0].plot(phi_plot, V_plot, linewidth=2, color="#2E86AB")

# æ ‡è®°è½¨è¿¹ç«¯ç‚¹ (Îµ=1)
for i, t60 in enumerate(trajectories_60):
    axes[0].scatter(t60["phi_end"], get_V(t60["phi_end"]), marker="x")
    axes[0].scatter(t60["phi_N"], get_V(t60["phi_N"]), marker="o")  # N=60

# Panel 3: ns-r å¹³é¢å åŠ  Planck åéªŒ
axes[2].contourf(ns, r, P_bk18, levels=[level_68, level_95])  # ç½®ä¿¡åŒºé—´
axes[2].scatter(t60["ns"], t60["r"], ...)  # æ¨¡å‹é¢„æµ‹
```

---

### ğŸ§¬ 5. SR Sub-Agent - ç¬¦å·å›å½’å­æ™ºèƒ½ä½“

**åŠŸèƒ½**: é…ç½®å¹¶è¿è¡Œ PySR ç¬¦å·å›å½’æœç´¢,è‡ªåŠ¨å‘ç°æ»¡è¶³è§‚æµ‹çº¦æŸçš„åŠ¿èƒ½è¡¨è¾¾å¼ã€‚

#### å·¥ä½œæµç¨‹

```mermaid
graph TD
    A[ä¸»æ™ºèƒ½ä½“å§”æ‰˜ä»»åŠ¡] --> B[SR Agent è§£æç‰©ç†ç›®æ ‡]
    B --> C[é…ç½® PySR å‚æ•°<br/>operators, constraints, maxsize]
    C --> D[è°ƒç”¨ search_potential]
    D --> E[åœ¨ç‹¬ç«‹è¿›ç¨‹è¿è¡Œ PySR]
    E --> F[Julia ç‰©ç†æ ¸å¿ƒè®¡ç®—æŸå¤±å‡½æ•°]
    F --> G[æ¼”åŒ–è¿­ä»£ 1-5 åˆ†é’Ÿ]
    G --> H[éªŒè¯å€™é€‰è¡¨è¾¾å¼]
    H --> I[è¿”å›æ’åç»“æœ<br/>expression, ns, r, loss]
```

#### Prompt è®¾è®¡è¦ç‚¹ ([agent.py:L91-L207](file:///home/phan635/HybridAutomata/baseline_ha/DeepInflation-pq/deepinflation/agent.py#L91-L207))

**é…ç½®åŸåˆ™**:
1. **ç®—ç¬¦é€‰æ‹©**: æ€»æ˜¯åŒ…å« `["+", "*"]`,æ ¹æ®éœ€è¦æ·»åŠ  `["^", "exp", "log"]`
2. **çº¦æŸæœºåˆ¶**:
   - `constraints`: é™åˆ¶ç®—ç¬¦å‚æ•°å¤æ‚åº¦,å¦‚ `{"^": [-1, 1]}` åªå…è®¸å¸¸æ•°æŒ‡æ•°
   - `nested_constraints`: ç¦æ­¢åµŒå¥—,å¦‚ `{"exp": {"exp": 0}}` é˜²æ­¢ `exp(exp(x))`
3. **å¤æ‚åº¦æ§åˆ¶**: `maxsize` é™åˆ¶è¡¨è¾¾å¼æ ‘å¤§å° (å…¸å‹ 12-30)

**ç¤ºä¾‹é…ç½®**:
```json
{
  "binary_operators": ["+", "*", "^"],
  "unary_operators": ["exp"],
  "constraints": {"^": [-1, 1]},
  "nested_constraints": {"exp": {"exp": 0}},
  "maxsize": 15,
  "niterations": 35
}
```

---

### ğŸ”¥ 6. SR Engine - ç¬¦å·å›å½’å¼•æ“ (sr_search.py)

**åŠŸèƒ½**: PySR å·¥å…·å‡½æ•° + Julia ç‰©ç†è®¡ç®—æ ¸å¿ƒã€‚

#### å…³é”®è®¾è®¡: è¿›ç¨‹éš”ç¦»

**ä¸ºä»€ä¹ˆéœ€è¦è¿›ç¨‹éš”ç¦»?** ([sr_search.py:L396-L407](file:///home/phan635/HybridAutomata/baseline_ha/DeepInflation-pq/deepinflation/sr_search.py#L396-L407))

```python
# ä½¿ç”¨ spawn ä¸Šä¸‹æ–‡ + max_tasks_per_child=1
# ç¡®ä¿æ¯æ¬¡ PySR è¿è¡Œåœ¨å…¨æ–°è¿›ç¨‹ä¸­,é¿å… Julia çº¿ç¨‹å†²çª
ctx = mp.get_context("spawn")
with ProcessPoolExecutor(max_workers=1, max_tasks_per_child=1, mp_context=ctx) as executor:
    result = executor.submit(_run_pysr, config).result(timeout=660)
```

#### Julia ç‰©ç†æ ¸å¿ƒ ([sr_search.py:L25-L208](file:///home/phan635/HybridAutomata/baseline_ha/DeepInflation-pq/deepinflation/sr_search.py#L25-L208))

**åµŒå…¥å¼ Julia æ¨¡å—**,ç›´æ¥ç¼–è¯‘åˆ° PySR è¿›ç¨‹ä¸­:

```julia
# è®¡ç®—æ…¢æ»šå‚æ•° Îµ
function epsilon(V, V_prime, phi, phi_min, phi_max)
    V_val, V_p = V(phi), V_prime(phi)
    return (M_P2 / 2) * (V_p / V_val)^2
end

# é€šè¿‡ ODE ç§¯åˆ†æ±‚ Ï†_N
function find_phi_N(V, V_prime, phi_end, bound)
    dphi_dN!(dphi, phi, p, N) = dphi[1] = M_P2 * V_prime(phi[1]) / V(phi[1])
    prob = ODEProblem(dphi_dN!, [phi_end], (0.0, N_OBS))
    sol = solve(prob; reltol=1e-4)
    return sol.u[end][1]  # è¿”å› N ä¸ª e-folds å¤„çš„ Ï† å€¼
end

# PySR æŸå¤±å‡½æ•°: Ï‡Â²/2
function compute_loss_julia(tree, dataset, options)
    # 1. è®¡ç®—è¡¨è¾¾å¼é¢„æµ‹å€¼
    prediction = eval_tree_array(tree, dataset.X, options)
    
    # 2. æ’å€¼æ„å»ºåŠ¿èƒ½å‡½æ•° V(Ï†)
    itp = cubic_spline_interpolation(phis, prediction)
    V(phi) = itp(phi)
    V_prime(phi) = Interpolations.gradient(itp, phi)[1]
    
    # 3. è®¡ç®—æ‰€æœ‰æœ‰æ•ˆè½¨è¿¹çš„ (ns, r)
    obs_list = compute_observables(V, V_prime, V_double_prime, phi_min, phi_max)
    
    # 4. è®¡ç®—æœ€å° Ï‡Â²
    chi2_min = min( ((ns - NS_OBS)/NS_SIGMA)^2 + ((r - R_OBS)/R_SIGMA)^2 )
    
    return chi2_min / 2
end
```

**æŸå¤±å‡½æ•°è®¾è®¡äº®ç‚¹**:
1. **è‡ªåŠ¨è½¨è¿¹æœç´¢**: ä¸éœ€è¦æ‰‹åŠ¨æŒ‡å®šåˆå§‹æ¡ä»¶,è‡ªåŠ¨æ‰¾åˆ°æ‰€æœ‰ Îµ=1 çš„ç«¯ç‚¹
2. **å¤šè½¨è¿¹å¤„ç†**: å–æ‰€æœ‰æœ‰æ•ˆè½¨è¿¹ä¸­ Ï‡Â² æœ€å°çš„
3. **æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥**: å¦‚æœ Ï‡Â² < 3,é¢å¤–åœ¨ç²—ç½‘æ ¼ä¸ŠéªŒè¯é˜²æ­¢è¿‡æ‹Ÿåˆ

---

### âš™ï¸ 7. Physics Kernel - ç‰©ç†è®¡ç®—å¼•æ“ (inflation.py)

**åŠŸèƒ½**: Python å®ç°çš„æš´èƒ€å®‡å®™å­¦æ ¸å¿ƒè®¡ç®—åº“,ä¸ Julia ç‰ˆæœ¬é€»è¾‘ä¸€è‡´ã€‚

#### æ ¸å¿ƒå‡½æ•°è°ƒç”¨é“¾

```
compute_observables_all_trajectories(expression)
  â”œâ”€ parse_potential(expression) â†’ V(Ï†)
  â”œâ”€ numerical_derivative â†’ V'(Ï†), V''(Ï†)
  â””â”€ compute_observables(V, V', V'', phi_min, phi_max)
      â”œâ”€ æ‰¾åˆ°æ‰€æœ‰ Îµ=1 çš„ç‚¹ (é€šè¿‡ brentq æ±‚æ ¹)
      â”œâ”€ å¯¹æ¯ä¸ª phi_end:
      â”‚   â”œâ”€ find_phi_N(N_values) â†’ æ±‚ phi_N
      â”‚   â””â”€ è®¡ç®—è§‚æµ‹é‡ ns, r, A_s
      â””â”€ è¿”å›æ‰€æœ‰æœ‰æ•ˆè½¨è¿¹
```

#### å…³é”®ç‰©ç†è®¡ç®—

**1. æ‰¾è½¨è¿¹ç«¯ç‚¹** ([inflation.py:L122-L136](file:///home/phan635/HybridAutomata/baseline_ha/DeepInflation-pq/deepinflation/inflation.py#L122-L136))

```python
# åœ¨ Ï† âˆˆ [phi_min, phi_max] å¯»æ‰¾ Îµ(Ï†) = 1 çš„ç‚¹
grid = np.linspace(phi_min, phi_max, 200)
eps_grid = [epsilon(V, V_prime, phi) for phi in grid]
sign_changes = np.where(np.diff(np.sign(eps_grid - 1.0)) != 0)[0]

# å¯¹æ¯ä¸ªç¬¦å·å˜åŒ–ç‚¹ç”¨äºŒåˆ†æ³•ç²¾ç¡®æ±‚æ ¹
for i in sign_changes:
    phi_end = brentq(lambda phi: epsilon(V, V_prime, phi) - 1.0, grid[i], grid[i+1])
```

**2. ç§¯åˆ†æ±‚ Ï†_N** ([inflation.py:L84-L114](file:///home/phan635/HybridAutomata/baseline_ha/DeepInflation-pq/deepinflation/inflation.py#L84-L114))

```python
def find_phi_N(V, V_prime, N_values, phi_end, bound):
    """
    æ±‚è§£ ODE: dÏ†/dN = M_PÂ² V'/V
    ä» Ï†_end ç§¯åˆ†åˆ° N âˆˆ [50, 55, 60]
    """
    def dphi_dN(phi):
        return M_P2 * V_prime(phi[0]) / V(phi[0])
    
    sol = solve_ivp(
        lambda N, phi: dphi_dN(phi),
        [0.0, max(N_values)],
        [phi_end],
        dense_output=True
    )
    
    # è¿”å›å­—å…¸ {50: phi_50, 55: phi_55, 60: phi_60}
    return {N: sol.sol(N)[0] for N in N_values}
```

**3. è§‚æµ‹é‡è®¡ç®—** ([inflation.py:L169-L189](file:///home/phan635/HybridAutomata/baseline_ha/DeepInflation-pq/deepinflation/inflation.py#L169-L189))

```python
eps_N = epsilon(V, V_prime, phi_N)
eta_N = M_P2 * V_double_prime(phi_N) / V(phi_N)

ns = 1.0 - 6.0*eps_N + 2.0*eta_N  # æ ‡é‡è°±æŒ‡æ•°
r = 16.0 * eps_N                  # å¼ æ ‡æ¯”
A_s = V(phi_N) / (24*Ï€Â²*M_PÂ²Â²*eps_N) * 1e9  # åŠŸç‡è°±å¹…åº¦
```

---

## ä¸‰ã€ç³»ç»Ÿäº¤äº’æµç¨‹ç¤ºä¾‹

### åœºæ™¯ 1: ç”¨æˆ·æŸ¥è¯¢ "V = phi^2 çš„ ns å’Œ r æ˜¯å¤šå°‘?"

```mermaid
sequenceDiagram
    participant U as User Interface
    participant MA as Main Agent
    participant T as Tools (analyze_potential)
    participant I as Inflation.py
    
    U->>MA: "V = phi^2 çš„ ns å’Œ r?"
    MA->>MA: å†³ç­–: è°ƒç”¨ analyze_potential
    MA->>T: analyze_potential("phi^2")
    T->>I: compute_observables_all_trajectories("phi^2")
    I->>I: 1. è§£æåŠ¿èƒ½ V(Ï†) = Ï†Â²<br/>2. è®¡ç®—å¯¼æ•°<br/>3. æ‰¾ Îµ=1 ç‚¹<br/>4. ç§¯åˆ†æ±‚ Ï†_N<br/>5. è®¡ç®— ns, r
    I-->>T: trajectories JSON
    T-->>MA: {"ns": 0.967, "r": 0.133, ...}
    MA->>MA: ç”Ÿæˆè‡ªç„¶è¯­è¨€è§£é‡Š
    MA-->>U: "å¯¹äº V=Ï†Â², nsâ‰ˆ0.967, râ‰ˆ0.133..."
```

### åœºæ™¯ 2: ç”¨æˆ·è¯·æ±‚ "æ‰¾ä¸€ä¸ªæ»¡è¶³ r < 0.01 çš„åŠ¿èƒ½"

```mermaid
sequenceDiagram
    participant U as User Interface
    participant MA as Main Agent
    participant SR as SR Sub-Agent
    participant PySR as SR Search (PySR)
    participant Julia as Julia Physics Kernel
    
    U->>MA: "æ‰¾ä¸€ä¸ª r < 0.01 çš„åŠ¿èƒ½"
    MA->>MA: å†³ç­–: å§”æ‰˜ç»™ SR Agent
    MA->>SR: delegate_task("find potential with r<0.01")
    SR->>SR: é…ç½®å‚æ•°:<br/>r_target=0.0<br/>r_sigma=0.01<br/>operators=["+", "*", "^", "exp"]
    SR->>PySR: search_potential(config_json)
    PySR->>PySR: å¯åŠ¨ç‹¬ç«‹è¿›ç¨‹
    PySR->>Julia: åŠ è½½ Julia æ¨¡å—
    loop æ¼”åŒ– 35 æ¬¡è¿­ä»£
        PySR->>Julia: è¯„ä¼°å€™é€‰è¡¨è¾¾å¼æŸå¤±
        Julia->>Julia: 1. è®¡ç®— V(Ï†)<br/>2. æ±‚è½¨è¿¹<br/>3. è®¡ç®— Ï‡Â²
        Julia-->>PySR: loss = Ï‡Â²/2
    end
    PySR->>PySR: éªŒè¯ top-20 å€™é€‰
    PySR-->>SR: results=[{expr, ns, r, loss}, ...]
    SR->>SR: åå¤„ç†: é€‰ top-3, ç®€åŒ–ç³»æ•°
    SR-->>MA: "æ‰¾åˆ° 3 ä¸ªå€™é€‰:<br/>1. (1-exp(-0.8*phi))^2 â†’ r=0.003"
    MA-->>U: å±•ç¤ºç»“æœ + å›¾è¡¨
```

---

## å››ã€å…³é”®æŠ€æœ¯ç‰¹ç‚¹æ€»ç»“

### 1. å¤šæ™ºèƒ½ä½“åä½œæ¶æ„
- **ä¸»æ™ºèƒ½ä½“**: å†³ç­–ä¸­å¿ƒ,æ ¹æ®è¯·æ±‚åˆ†å‘ä»»åŠ¡
- **SR å­æ™ºèƒ½ä½“**: ä¸“å®¶ç³»ç»Ÿ,ä¸“æ³¨ç¬¦å·å›å½’é…ç½®
- **å·¥å…·é›†**: ç‰©ç†è®¡ç®—ã€ç»˜å›¾ã€çŸ¥è¯†æ£€ç´¢

### 2. æ··åˆè®¡ç®—å¼•æ“
- **Python**: ç”¨æˆ·ç•Œé¢ã€æ™ºèƒ½ä½“é€»è¾‘ã€é¢„å¤„ç†
- **Julia**: é«˜æ€§èƒ½ç‰©ç†è®¡ç®— (ODE æ±‚è§£ã€æ•°å€¼ç§¯åˆ†)
- **è¿›ç¨‹éš”ç¦»**: é¿å… Julia/Python å¤šçº¿ç¨‹å†²çª

### 3. çŸ¥è¯†å¢å¼º RAG
- **Parent Document Retrieval**: ç²¾ç¡®æ£€ç´¢ + å®Œæ•´ä¸Šä¸‹æ–‡
- **æ··åˆæ£€ç´¢**: è¯­ä¹‰ç›¸ä¼¼åº¦ + BM25 å…³é”®è¯
- **70+ æš´èƒ€æ¨¡å‹**: æ¥è‡ª arXiv:1303.3787

### 4. ç‰©ç†çº¦æŸçš„ç¬¦å·å›å½’
- **è‡ªå®šä¹‰æŸå¤±å‡½æ•°**: Ï‡Â² åŸºäºç‰©ç†è§‚æµ‹é‡ (ns, r)
- **è¡¨è¾¾å¼çº¦æŸ**: é€šè¿‡ `constraints` æ§åˆ¶æœç´¢ç©ºé—´
- **è‡ªåŠ¨éªŒè¯**: Python ä¾§é‡æ–°è®¡ç®—ç¡®ä¿æ­£ç¡®æ€§

### 5. æµå¼ç”¨æˆ·ä½“éªŒ
- **å®æ—¶å·¥å…·çŠ¶æ€**: æ˜¾ç¤ºå·¥å…·è°ƒç”¨è¿›åº¦
- **æµå¼æ–‡æœ¬è¾“å‡º**: å‡å°‘ç­‰å¾…æ„ŸçŸ¥
- **å¯è§†åŒ–åé¦ˆ**: è‡ªåŠ¨ç”Ÿæˆè¯Šæ–­å›¾è¡¨

---

## äº”ã€ä½¿ç”¨ç¤ºä¾‹

### å¯åŠ¨ Web ç•Œé¢
```bash
python app.py
# è®¿é—® http://127.0.0.1:7860
```

### CLI æ¨¡å¼
```bash
python -m deepinflation.agent
> What is ns for V = phi^2?
> Plot the Starobinsky model
> Find a plateau potential with r < 0.01
```

### ç¼–ç¨‹æ¥å£
```python
from deepinflation.agent import DeepInflation

agent = DeepInflation(api_key="sk-...", model="gpt-5.2")

# åŒæ­¥æ¨¡å¼
response = agent.run("Analyze V = phi^2")

# å¼‚æ­¥æµå¼æ¨¡å¼
async for event in agent.stream("Find potential with nsâ‰ˆ0.965"):
    if event["type"] == "response":
        print(event["content"])
```

---

## å…­ã€æ–‡ä»¶ç»“æ„æ€»è§ˆ

```
DeepInflation-pq/
â”œâ”€â”€ app.py                      # Gradio Web ç•Œé¢
â”œâ”€â”€ deepinflation/
â”‚   â”œâ”€â”€ agent.py               # ä¸»æ™ºèƒ½ä½“ + SR å­æ™ºèƒ½ä½“
â”‚   â”œâ”€â”€ inflation.py           # Python ç‰©ç†è®¡ç®—å¼•æ“
â”‚   â”œâ”€â”€ tools.py               # åˆ†æä¸ç»˜å›¾å·¥å…·
â”‚   â”œâ”€â”€ sr_search.py           # PySR + Julia ç¬¦å·å›å½’
â”‚   â””â”€â”€ encyclopedia_rag.py    # RAG çŸ¥è¯†åº“
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ models/                # 70+ æš´èƒ€æ¨¡å‹ Markdown æ–‡æ¡£
â”‚   â”œâ”€â”€ model_list.json        # æ¨¡å‹å…ƒæ•°æ®
â”‚   â””â”€â”€ bk18_planck_posterior.npz  # Planck+BK18 è§‚æµ‹æ•°æ®
â””â”€â”€ tmp/
    â”œâ”€â”€ lancedb/               # å‘é‡æ•°æ®åº“
    â””â”€â”€ agent_storage.db       # å¯¹è¯å†å²
```

---

è¿™ä¸ªç³»ç»Ÿå·§å¦™åœ°ç»“åˆäº† **å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›**ã€**ç¬¦å·å›å½’çš„è‡ªåŠ¨å‘ç°èƒ½åŠ›** å’Œ **ç‰©ç†è®¡ç®—çš„ç²¾ç¡®æ€§**,ä¸ºæš´èƒ€å®‡å®™å­¦ç ”ç©¶æä¾›äº†ä¸€ä¸ªæ™ºèƒ½åŒ–çš„åˆ†æå¹³å°ã€‚é€šè¿‡å¤šæ™ºèƒ½ä½“åä½œå’Œå·¥å…·ç¼–æ’,ç”¨æˆ·å¯ä»¥ç”¨è‡ªç„¶è¯­è¨€ä¸ç³»ç»Ÿäº¤äº’,å¿«é€Ÿå®Œæˆå¤æ‚çš„ç‰©ç†è®¡ç®—å’Œæ¨¡å‹æ¢ç´¢ä»»åŠ¡ã€‚
